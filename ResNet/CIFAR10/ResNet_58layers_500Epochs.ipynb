{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"ResNet_58layers_500Epochs.ipynb","provenance":[{"file_id":"1qf3GtNkBdd7gK3LzDy72ve2SrWHsgGyM","timestamp":1592909675456},{"file_id":"https://github.com/Taejin1221/MachineLearning/blob/master/ResNet.ipynb","timestamp":1591852226402}],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"r4RUB4HR0BYp","colab_type":"code","colab":{}},"source":["from google.colab import drive # for google colab\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8jW0OUJRA5Xe","colab_type":"code","colab":{}},"source":["import os\n","os.chdir('drive/My Drive/Colab Notebooks/') # Drive directory"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8iJg6AkLyQ-o","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras import datasets"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Uh2roVZhyQ-r","colab_type":"code","colab":{}},"source":["n = 9"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bKRNI2q2yQ-u","colab_type":"code","colab":{}},"source":["inputs = keras.Input( shape = ( 32, 32, 3 ), name = 'input' )\n","\n","identity = layers.Conv2D( filters = 16, kernel_size = [ 7, 7 ], padding = 'Same', activation = 'relu' )(inputs)\n","\n","# block 1\n","for _ in range( n ):\n","    output = layers.Conv2D( filters = 16, kernel_size = [ 3, 3 ], padding = 'Same' )(identity)\n","    output = layers.BatchNormalization()(output)\n","    output = layers.Activation('relu')(output)\n","    \n","    output = layers.Conv2D( filters = 16, kernel_size = [ 3, 3 ],\n","                           padding = 'Same' )(output)\n","    output = layers.BatchNormalization()(output)\n","    \n","    output = layers.Add()( [ output, identity ] )\n","    identity = layers.Activation('relu')(output)\n","\n","identity = layers.MaxPooling2D( pool_size = [ 3, 3 ], padding = 'same',\n","                               strides = 2 )(identity)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"l_84Z42LyQ-w","colab_type":"code","colab":{}},"source":["# block 2\n","identity = layers.ZeroPadding2D( [ 0, 8 ], 'channels_first' )(identity)\n","for _ in range( n ):\n","    output = layers.Conv2D( filters = 32, kernel_size = [ 3, 3 ],\n","                           padding = 'Same' )(identity)\n","    output = layers.BatchNormalization()(output)\n","    output = layers.Activation('relu')(output)\n","    \n","    output = layers.Conv2D( filters = 32, kernel_size = [ 3, 3 ],\n","                           padding = 'Same' )(output)\n","    output = layers.BatchNormalization()(output)\n","    \n","    output = layers.Add()( [ output, identity ] )\n","    identity = layers.Activation('relu')(output)\n","\n","identity = layers.MaxPooling2D( pool_size = [ 3, 3 ], padding = 'same',\n","                               strides = 2 )(identity)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"18FDc_f9yQ-y","colab_type":"code","colab":{}},"source":["# block 3\n","identity = layers.ZeroPadding2D( [ 0, 16 ], 'channels_first' )(identity)\n","for _ in range( n ):\n","    output = layers.Conv2D( filters = 64, kernel_size = [ 3, 3 ],\n","                           padding = 'Same' )(identity)\n","    output = layers.BatchNormalization()(output)\n","    output = layers.Activation('relu')(output)\n","    \n","    output = layers.Conv2D( filters = 64, kernel_size = [ 3, 3 ],\n","                           padding = 'Same' )(output)\n","    output = layers.BatchNormalization()(output)\n","    \n","    output = layers.Add()( [ output, identity ] )\n","    identity = layers.Activation('relu')(output)\n","\n","identity = layers.MaxPooling2D( pool_size = [ 3, 3 ], padding = 'same',\n","                               strides = 2 )(identity)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QgZp3nGByQ-1","colab_type":"code","colab":{}},"source":["output = layers.GlobalAveragePooling2D()(identity)\n","output = layers.Dense( 128, activation = 'relu' )(output)\n","output = layers.Dense( 128, activation = 'relu' )(output)\n","output = layers.Dense( 10, activation = 'softmax' )(output)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"xeulYwgYyQ-3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1592919534013,"user_tz":-540,"elapsed":12679,"user":{"displayName":"안태진","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsxFAp9n5vXMpfFrx0yqs7oGvvO0UQmgnJGXAJw=s64","userId":"04391961696214707238"}},"outputId":"38a5acfc-0d23-408b-f7a9-7dfa1f19f866"},"source":["model = keras.Model( inputs = inputs, outputs = output, name = 'resnet' )\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"resnet\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input (InputLayer)              [(None, 32, 32, 3)]  0                                            \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 32, 32, 16)   2368        input[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 32, 32, 16)   2320        conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 32, 32, 16)   64          conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 32, 32, 16)   0           batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 32, 32, 16)   2320        activation[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","add (Add)                       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      \n","                                                                 conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 32, 32, 16)   0           add[0][0]                        \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 32, 32, 16)   2320        activation_1[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 32, 32, 16)   2320        activation_2[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          conv2d_4[0][0]                   \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 32, 32, 16)   0           batch_normalization_3[0][0]      \n","                                                                 activation_1[0][0]               \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 32, 32, 16)   0           add_1[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 32, 32, 16)   2320        activation_3[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 32, 32, 16)   64          conv2d_5[0][0]                   \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 32, 32, 16)   0           batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 32, 32, 16)   2320        activation_4[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_5 (BatchNor (None, 32, 32, 16)   64          conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","add_2 (Add)                     (None, 32, 32, 16)   0           batch_normalization_5[0][0]      \n","                                                                 activation_3[0][0]               \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 32, 32, 16)   0           add_2[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 32, 32, 16)   2320        activation_5[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_6 (BatchNor (None, 32, 32, 16)   64          conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 32, 32, 16)   0           batch_normalization_6[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 32, 32, 16)   2320        activation_6[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_7 (BatchNor (None, 32, 32, 16)   64          conv2d_8[0][0]                   \n","__________________________________________________________________________________________________\n","add_3 (Add)                     (None, 32, 32, 16)   0           batch_normalization_7[0][0]      \n","                                                                 activation_5[0][0]               \n","__________________________________________________________________________________________________\n","activation_7 (Activation)       (None, 32, 32, 16)   0           add_3[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 32, 32, 16)   2320        activation_7[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_8 (BatchNor (None, 32, 32, 16)   64          conv2d_9[0][0]                   \n","__________________________________________________________________________________________________\n","activation_8 (Activation)       (None, 32, 32, 16)   0           batch_normalization_8[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 32, 32, 16)   2320        activation_8[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_9 (BatchNor (None, 32, 32, 16)   64          conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","add_4 (Add)                     (None, 32, 32, 16)   0           batch_normalization_9[0][0]      \n","                                                                 activation_7[0][0]               \n","__________________________________________________________________________________________________\n","activation_9 (Activation)       (None, 32, 32, 16)   0           add_4[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 32, 32, 16)   2320        activation_9[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_10 (BatchNo (None, 32, 32, 16)   64          conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","activation_10 (Activation)      (None, 32, 32, 16)   0           batch_normalization_10[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 32, 32, 16)   2320        activation_10[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_11 (BatchNo (None, 32, 32, 16)   64          conv2d_12[0][0]                  \n","__________________________________________________________________________________________________\n","add_5 (Add)                     (None, 32, 32, 16)   0           batch_normalization_11[0][0]     \n","                                                                 activation_9[0][0]               \n","__________________________________________________________________________________________________\n","activation_11 (Activation)      (None, 32, 32, 16)   0           add_5[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 32, 32, 16)   2320        activation_11[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_12 (BatchNo (None, 32, 32, 16)   64          conv2d_13[0][0]                  \n","__________________________________________________________________________________________________\n","activation_12 (Activation)      (None, 32, 32, 16)   0           batch_normalization_12[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 32, 32, 16)   2320        activation_12[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_13 (BatchNo (None, 32, 32, 16)   64          conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","add_6 (Add)                     (None, 32, 32, 16)   0           batch_normalization_13[0][0]     \n","                                                                 activation_11[0][0]              \n","__________________________________________________________________________________________________\n","activation_13 (Activation)      (None, 32, 32, 16)   0           add_6[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 32, 32, 16)   2320        activation_13[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_14 (BatchNo (None, 32, 32, 16)   64          conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","activation_14 (Activation)      (None, 32, 32, 16)   0           batch_normalization_14[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 32, 32, 16)   2320        activation_14[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_15 (BatchNo (None, 32, 32, 16)   64          conv2d_16[0][0]                  \n","__________________________________________________________________________________________________\n","add_7 (Add)                     (None, 32, 32, 16)   0           batch_normalization_15[0][0]     \n","                                                                 activation_13[0][0]              \n","__________________________________________________________________________________________________\n","activation_15 (Activation)      (None, 32, 32, 16)   0           add_7[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 32, 32, 16)   2320        activation_15[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_16 (BatchNo (None, 32, 32, 16)   64          conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","activation_16 (Activation)      (None, 32, 32, 16)   0           batch_normalization_16[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_18 (Conv2D)              (None, 32, 32, 16)   2320        activation_16[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_17 (BatchNo (None, 32, 32, 16)   64          conv2d_18[0][0]                  \n","__________________________________________________________________________________________________\n","add_8 (Add)                     (None, 32, 32, 16)   0           batch_normalization_17[0][0]     \n","                                                                 activation_15[0][0]              \n","__________________________________________________________________________________________________\n","activation_17 (Activation)      (None, 32, 32, 16)   0           add_8[0][0]                      \n","__________________________________________________________________________________________________\n","max_pooling2d (MaxPooling2D)    (None, 16, 16, 16)   0           activation_17[0][0]              \n","__________________________________________________________________________________________________\n","zero_padding2d (ZeroPadding2D)  (None, 16, 16, 32)   0           max_pooling2d[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_19 (Conv2D)              (None, 16, 16, 32)   9248        zero_padding2d[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_18 (BatchNo (None, 16, 16, 32)   128         conv2d_19[0][0]                  \n","__________________________________________________________________________________________________\n","activation_18 (Activation)      (None, 16, 16, 32)   0           batch_normalization_18[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_20 (Conv2D)              (None, 16, 16, 32)   9248        activation_18[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_19 (BatchNo (None, 16, 16, 32)   128         conv2d_20[0][0]                  \n","__________________________________________________________________________________________________\n","add_9 (Add)                     (None, 16, 16, 32)   0           batch_normalization_19[0][0]     \n","                                                                 zero_padding2d[0][0]             \n","__________________________________________________________________________________________________\n","activation_19 (Activation)      (None, 16, 16, 32)   0           add_9[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_21 (Conv2D)              (None, 16, 16, 32)   9248        activation_19[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_20 (BatchNo (None, 16, 16, 32)   128         conv2d_21[0][0]                  \n","__________________________________________________________________________________________________\n","activation_20 (Activation)      (None, 16, 16, 32)   0           batch_normalization_20[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_22 (Conv2D)              (None, 16, 16, 32)   9248        activation_20[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_21 (BatchNo (None, 16, 16, 32)   128         conv2d_22[0][0]                  \n","__________________________________________________________________________________________________\n","add_10 (Add)                    (None, 16, 16, 32)   0           batch_normalization_21[0][0]     \n","                                                                 activation_19[0][0]              \n","__________________________________________________________________________________________________\n","activation_21 (Activation)      (None, 16, 16, 32)   0           add_10[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_23 (Conv2D)              (None, 16, 16, 32)   9248        activation_21[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_22 (BatchNo (None, 16, 16, 32)   128         conv2d_23[0][0]                  \n","__________________________________________________________________________________________________\n","activation_22 (Activation)      (None, 16, 16, 32)   0           batch_normalization_22[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_24 (Conv2D)              (None, 16, 16, 32)   9248        activation_22[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_23 (BatchNo (None, 16, 16, 32)   128         conv2d_24[0][0]                  \n","__________________________________________________________________________________________________\n","add_11 (Add)                    (None, 16, 16, 32)   0           batch_normalization_23[0][0]     \n","                                                                 activation_21[0][0]              \n","__________________________________________________________________________________________________\n","activation_23 (Activation)      (None, 16, 16, 32)   0           add_11[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_25 (Conv2D)              (None, 16, 16, 32)   9248        activation_23[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_24 (BatchNo (None, 16, 16, 32)   128         conv2d_25[0][0]                  \n","__________________________________________________________________________________________________\n","activation_24 (Activation)      (None, 16, 16, 32)   0           batch_normalization_24[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_26 (Conv2D)              (None, 16, 16, 32)   9248        activation_24[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_25 (BatchNo (None, 16, 16, 32)   128         conv2d_26[0][0]                  \n","__________________________________________________________________________________________________\n","add_12 (Add)                    (None, 16, 16, 32)   0           batch_normalization_25[0][0]     \n","                                                                 activation_23[0][0]              \n","__________________________________________________________________________________________________\n","activation_25 (Activation)      (None, 16, 16, 32)   0           add_12[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_27 (Conv2D)              (None, 16, 16, 32)   9248        activation_25[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_26 (BatchNo (None, 16, 16, 32)   128         conv2d_27[0][0]                  \n","__________________________________________________________________________________________________\n","activation_26 (Activation)      (None, 16, 16, 32)   0           batch_normalization_26[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_28 (Conv2D)              (None, 16, 16, 32)   9248        activation_26[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_27 (BatchNo (None, 16, 16, 32)   128         conv2d_28[0][0]                  \n","__________________________________________________________________________________________________\n","add_13 (Add)                    (None, 16, 16, 32)   0           batch_normalization_27[0][0]     \n","                                                                 activation_25[0][0]              \n","__________________________________________________________________________________________________\n","activation_27 (Activation)      (None, 16, 16, 32)   0           add_13[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_29 (Conv2D)              (None, 16, 16, 32)   9248        activation_27[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_28 (BatchNo (None, 16, 16, 32)   128         conv2d_29[0][0]                  \n","__________________________________________________________________________________________________\n","activation_28 (Activation)      (None, 16, 16, 32)   0           batch_normalization_28[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_30 (Conv2D)              (None, 16, 16, 32)   9248        activation_28[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_29 (BatchNo (None, 16, 16, 32)   128         conv2d_30[0][0]                  \n","__________________________________________________________________________________________________\n","add_14 (Add)                    (None, 16, 16, 32)   0           batch_normalization_29[0][0]     \n","                                                                 activation_27[0][0]              \n","__________________________________________________________________________________________________\n","activation_29 (Activation)      (None, 16, 16, 32)   0           add_14[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_31 (Conv2D)              (None, 16, 16, 32)   9248        activation_29[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_30 (BatchNo (None, 16, 16, 32)   128         conv2d_31[0][0]                  \n","__________________________________________________________________________________________________\n","activation_30 (Activation)      (None, 16, 16, 32)   0           batch_normalization_30[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_32 (Conv2D)              (None, 16, 16, 32)   9248        activation_30[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_31 (BatchNo (None, 16, 16, 32)   128         conv2d_32[0][0]                  \n","__________________________________________________________________________________________________\n","add_15 (Add)                    (None, 16, 16, 32)   0           batch_normalization_31[0][0]     \n","                                                                 activation_29[0][0]              \n","__________________________________________________________________________________________________\n","activation_31 (Activation)      (None, 16, 16, 32)   0           add_15[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_33 (Conv2D)              (None, 16, 16, 32)   9248        activation_31[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_32 (BatchNo (None, 16, 16, 32)   128         conv2d_33[0][0]                  \n","__________________________________________________________________________________________________\n","activation_32 (Activation)      (None, 16, 16, 32)   0           batch_normalization_32[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_34 (Conv2D)              (None, 16, 16, 32)   9248        activation_32[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_33 (BatchNo (None, 16, 16, 32)   128         conv2d_34[0][0]                  \n","__________________________________________________________________________________________________\n","add_16 (Add)                    (None, 16, 16, 32)   0           batch_normalization_33[0][0]     \n","                                                                 activation_31[0][0]              \n","__________________________________________________________________________________________________\n","activation_33 (Activation)      (None, 16, 16, 32)   0           add_16[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_35 (Conv2D)              (None, 16, 16, 32)   9248        activation_33[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_34 (BatchNo (None, 16, 16, 32)   128         conv2d_35[0][0]                  \n","__________________________________________________________________________________________________\n","activation_34 (Activation)      (None, 16, 16, 32)   0           batch_normalization_34[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_36 (Conv2D)              (None, 16, 16, 32)   9248        activation_34[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_35 (BatchNo (None, 16, 16, 32)   128         conv2d_36[0][0]                  \n","__________________________________________________________________________________________________\n","add_17 (Add)                    (None, 16, 16, 32)   0           batch_normalization_35[0][0]     \n","                                                                 activation_33[0][0]              \n","__________________________________________________________________________________________________\n","activation_35 (Activation)      (None, 16, 16, 32)   0           add_17[0][0]                     \n","__________________________________________________________________________________________________\n","max_pooling2d_1 (MaxPooling2D)  (None, 8, 8, 32)     0           activation_35[0][0]              \n","__________________________________________________________________________________________________\n","zero_padding2d_1 (ZeroPadding2D (None, 8, 8, 64)     0           max_pooling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_37 (Conv2D)              (None, 8, 8, 64)     36928       zero_padding2d_1[0][0]           \n","__________________________________________________________________________________________________\n","batch_normalization_36 (BatchNo (None, 8, 8, 64)     256         conv2d_37[0][0]                  \n","__________________________________________________________________________________________________\n","activation_36 (Activation)      (None, 8, 8, 64)     0           batch_normalization_36[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_38 (Conv2D)              (None, 8, 8, 64)     36928       activation_36[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_37 (BatchNo (None, 8, 8, 64)     256         conv2d_38[0][0]                  \n","__________________________________________________________________________________________________\n","add_18 (Add)                    (None, 8, 8, 64)     0           batch_normalization_37[0][0]     \n","                                                                 zero_padding2d_1[0][0]           \n","__________________________________________________________________________________________________\n","activation_37 (Activation)      (None, 8, 8, 64)     0           add_18[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_39 (Conv2D)              (None, 8, 8, 64)     36928       activation_37[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_38 (BatchNo (None, 8, 8, 64)     256         conv2d_39[0][0]                  \n","__________________________________________________________________________________________________\n","activation_38 (Activation)      (None, 8, 8, 64)     0           batch_normalization_38[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_40 (Conv2D)              (None, 8, 8, 64)     36928       activation_38[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_39 (BatchNo (None, 8, 8, 64)     256         conv2d_40[0][0]                  \n","__________________________________________________________________________________________________\n","add_19 (Add)                    (None, 8, 8, 64)     0           batch_normalization_39[0][0]     \n","                                                                 activation_37[0][0]              \n","__________________________________________________________________________________________________\n","activation_39 (Activation)      (None, 8, 8, 64)     0           add_19[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_41 (Conv2D)              (None, 8, 8, 64)     36928       activation_39[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_40 (BatchNo (None, 8, 8, 64)     256         conv2d_41[0][0]                  \n","__________________________________________________________________________________________________\n","activation_40 (Activation)      (None, 8, 8, 64)     0           batch_normalization_40[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_42 (Conv2D)              (None, 8, 8, 64)     36928       activation_40[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_41 (BatchNo (None, 8, 8, 64)     256         conv2d_42[0][0]                  \n","__________________________________________________________________________________________________\n","add_20 (Add)                    (None, 8, 8, 64)     0           batch_normalization_41[0][0]     \n","                                                                 activation_39[0][0]              \n","__________________________________________________________________________________________________\n","activation_41 (Activation)      (None, 8, 8, 64)     0           add_20[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_43 (Conv2D)              (None, 8, 8, 64)     36928       activation_41[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_42 (BatchNo (None, 8, 8, 64)     256         conv2d_43[0][0]                  \n","__________________________________________________________________________________________________\n","activation_42 (Activation)      (None, 8, 8, 64)     0           batch_normalization_42[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_44 (Conv2D)              (None, 8, 8, 64)     36928       activation_42[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_43 (BatchNo (None, 8, 8, 64)     256         conv2d_44[0][0]                  \n","__________________________________________________________________________________________________\n","add_21 (Add)                    (None, 8, 8, 64)     0           batch_normalization_43[0][0]     \n","                                                                 activation_41[0][0]              \n","__________________________________________________________________________________________________\n","activation_43 (Activation)      (None, 8, 8, 64)     0           add_21[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_45 (Conv2D)              (None, 8, 8, 64)     36928       activation_43[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_44 (BatchNo (None, 8, 8, 64)     256         conv2d_45[0][0]                  \n","__________________________________________________________________________________________________\n","activation_44 (Activation)      (None, 8, 8, 64)     0           batch_normalization_44[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_46 (Conv2D)              (None, 8, 8, 64)     36928       activation_44[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_45 (BatchNo (None, 8, 8, 64)     256         conv2d_46[0][0]                  \n","__________________________________________________________________________________________________\n","add_22 (Add)                    (None, 8, 8, 64)     0           batch_normalization_45[0][0]     \n","                                                                 activation_43[0][0]              \n","__________________________________________________________________________________________________\n","activation_45 (Activation)      (None, 8, 8, 64)     0           add_22[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_47 (Conv2D)              (None, 8, 8, 64)     36928       activation_45[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_46 (BatchNo (None, 8, 8, 64)     256         conv2d_47[0][0]                  \n","__________________________________________________________________________________________________\n","activation_46 (Activation)      (None, 8, 8, 64)     0           batch_normalization_46[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_48 (Conv2D)              (None, 8, 8, 64)     36928       activation_46[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_47 (BatchNo (None, 8, 8, 64)     256         conv2d_48[0][0]                  \n","__________________________________________________________________________________________________\n","add_23 (Add)                    (None, 8, 8, 64)     0           batch_normalization_47[0][0]     \n","                                                                 activation_45[0][0]              \n","__________________________________________________________________________________________________\n","activation_47 (Activation)      (None, 8, 8, 64)     0           add_23[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_49 (Conv2D)              (None, 8, 8, 64)     36928       activation_47[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_48 (BatchNo (None, 8, 8, 64)     256         conv2d_49[0][0]                  \n","__________________________________________________________________________________________________\n","activation_48 (Activation)      (None, 8, 8, 64)     0           batch_normalization_48[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_50 (Conv2D)              (None, 8, 8, 64)     36928       activation_48[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_49 (BatchNo (None, 8, 8, 64)     256         conv2d_50[0][0]                  \n","__________________________________________________________________________________________________\n","add_24 (Add)                    (None, 8, 8, 64)     0           batch_normalization_49[0][0]     \n","                                                                 activation_47[0][0]              \n","__________________________________________________________________________________________________\n","activation_49 (Activation)      (None, 8, 8, 64)     0           add_24[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_51 (Conv2D)              (None, 8, 8, 64)     36928       activation_49[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_50 (BatchNo (None, 8, 8, 64)     256         conv2d_51[0][0]                  \n","__________________________________________________________________________________________________\n","activation_50 (Activation)      (None, 8, 8, 64)     0           batch_normalization_50[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_52 (Conv2D)              (None, 8, 8, 64)     36928       activation_50[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_51 (BatchNo (None, 8, 8, 64)     256         conv2d_52[0][0]                  \n","__________________________________________________________________________________________________\n","add_25 (Add)                    (None, 8, 8, 64)     0           batch_normalization_51[0][0]     \n","                                                                 activation_49[0][0]              \n","__________________________________________________________________________________________________\n","activation_51 (Activation)      (None, 8, 8, 64)     0           add_25[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_53 (Conv2D)              (None, 8, 8, 64)     36928       activation_51[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_52 (BatchNo (None, 8, 8, 64)     256         conv2d_53[0][0]                  \n","__________________________________________________________________________________________________\n","activation_52 (Activation)      (None, 8, 8, 64)     0           batch_normalization_52[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_54 (Conv2D)              (None, 8, 8, 64)     36928       activation_52[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_53 (BatchNo (None, 8, 8, 64)     256         conv2d_54[0][0]                  \n","__________________________________________________________________________________________________\n","add_26 (Add)                    (None, 8, 8, 64)     0           batch_normalization_53[0][0]     \n","                                                                 activation_51[0][0]              \n","__________________________________________________________________________________________________\n","activation_53 (Activation)      (None, 8, 8, 64)     0           add_26[0][0]                     \n","__________________________________________________________________________________________________\n","max_pooling2d_2 (MaxPooling2D)  (None, 4, 4, 64)     0           activation_53[0][0]              \n","__________________________________________________________________________________________________\n","global_average_pooling2d (Globa (None, 64)           0           max_pooling2d_2[0][0]            \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 128)          8320        global_average_pooling2d[0][0]   \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 128)          16512       dense[0][0]                      \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 10)           1290        dense_1[0][0]                    \n","==================================================================================================\n","Total params: 909,482\n","Trainable params: 905,450\n","Non-trainable params: 4,032\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qxH_h9i2yQ-7","colab_type":"code","colab":{}},"source":["# Hyper Parameters\n","lr = 1e-3\n","BATCH_SIZE = 512\n","EPOCHS = 500\n","model_name = 'ResNet_58Layers(500Epochs, Modified1)'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z52y4GRPyQ-9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1592919539015,"user_tz":-540,"elapsed":17672,"user":{"displayName":"안태진","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsxFAp9n5vXMpfFrx0yqs7oGvvO0UQmgnJGXAJw=s64","userId":"04391961696214707238"}},"outputId":"7d1dff06-4e0b-46a8-e4df-20f5e082f32c"},"source":["(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n","\n","x_train = x_train.astype('float32') / 255.0\n","x_test = x_test.astype('float32') / 255.0\n","y_train = keras.utils.to_categorical( y_train, 10 )\n","y_test = keras.utils.to_categorical( y_test, 10 )\n","\n","model.compile( optimizer = keras.optimizers.RMSprop( lr, 0.9 ),\n","             loss = keras.losses.CategoricalCrossentropy( from_logits = True ),\n","              metrics = ['acc'])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170500096/170498071 [==============================] - 2s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"scrolled":true,"id":"z9BjknwUyQ-_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1592945274140,"user_tz":-540,"elapsed":25752790,"user":{"displayName":"안태진","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsxFAp9n5vXMpfFrx0yqs7oGvvO0UQmgnJGXAJw=s64","userId":"04391961696214707238"}},"outputId":"a17d5741-89d8-4106-81f4-70799d35ef12"},"source":["history = model.fit( x_train, y_train, batch_size = BATCH_SIZE,\n","                    epochs = EPOCHS, validation_split = 0.2 )"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/500\n","79/79 [==============================] - 52s 658ms/step - loss: 2.2215 - acc: 0.2303 - val_loss: 2.3241 - val_acc: 0.0997\n","Epoch 2/500\n","79/79 [==============================] - 51s 641ms/step - loss: 2.1176 - acc: 0.3381 - val_loss: 2.2509 - val_acc: 0.2025\n","Epoch 3/500\n","79/79 [==============================] - 51s 641ms/step - loss: 2.0802 - acc: 0.3759 - val_loss: 2.2507 - val_acc: 0.2040\n","Epoch 4/500\n","79/79 [==============================] - 51s 640ms/step - loss: 2.0484 - acc: 0.4067 - val_loss: 2.2707 - val_acc: 0.1812\n","Epoch 5/500\n","79/79 [==============================] - 51s 640ms/step - loss: 2.0190 - acc: 0.4382 - val_loss: 2.1719 - val_acc: 0.2847\n","Epoch 6/500\n","79/79 [==============================] - 51s 642ms/step - loss: 1.9986 - acc: 0.4573 - val_loss: 2.2759 - val_acc: 0.1796\n","Epoch 7/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.9779 - acc: 0.4791 - val_loss: 2.2598 - val_acc: 0.1989\n","Epoch 8/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.9559 - acc: 0.5012 - val_loss: 2.1647 - val_acc: 0.2945\n","Epoch 9/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.9089 - acc: 0.5483 - val_loss: 2.1289 - val_acc: 0.3291\n","Epoch 10/500\n","79/79 [==============================] - 51s 639ms/step - loss: 1.8821 - acc: 0.5757 - val_loss: 2.1323 - val_acc: 0.3257\n","Epoch 11/500\n","79/79 [==============================] - 51s 641ms/step - loss: 1.8597 - acc: 0.5985 - val_loss: 2.1229 - val_acc: 0.3340\n","Epoch 12/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.8428 - acc: 0.6159 - val_loss: 2.0414 - val_acc: 0.4162\n","Epoch 13/500\n","79/79 [==============================] - 51s 646ms/step - loss: 1.8243 - acc: 0.6348 - val_loss: 2.0176 - val_acc: 0.4384\n","Epoch 14/500\n","79/79 [==============================] - 51s 646ms/step - loss: 1.8097 - acc: 0.6492 - val_loss: 2.0076 - val_acc: 0.4494\n","Epoch 15/500\n","79/79 [==============================] - 51s 646ms/step - loss: 1.7944 - acc: 0.6654 - val_loss: 1.9131 - val_acc: 0.5455\n","Epoch 16/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.7825 - acc: 0.6766 - val_loss: 2.1884 - val_acc: 0.2696\n","Epoch 17/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.7710 - acc: 0.6887 - val_loss: 2.2101 - val_acc: 0.2480\n","Epoch 18/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.7655 - acc: 0.6939 - val_loss: 2.1325 - val_acc: 0.3259\n","Epoch 19/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.7586 - acc: 0.7005 - val_loss: 2.1367 - val_acc: 0.3206\n","Epoch 20/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.7483 - acc: 0.7117 - val_loss: 1.8752 - val_acc: 0.5847\n","Epoch 21/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.7425 - acc: 0.7171 - val_loss: 1.9148 - val_acc: 0.5423\n","Epoch 22/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.7385 - acc: 0.7209 - val_loss: 1.9005 - val_acc: 0.5590\n","Epoch 23/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.7359 - acc: 0.7237 - val_loss: 2.0064 - val_acc: 0.4530\n","Epoch 24/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.7280 - acc: 0.7318 - val_loss: 1.9266 - val_acc: 0.5314\n","Epoch 25/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.7195 - acc: 0.7398 - val_loss: 2.0988 - val_acc: 0.3611\n","Epoch 26/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.7166 - acc: 0.7425 - val_loss: 1.9494 - val_acc: 0.5096\n","Epoch 27/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.7121 - acc: 0.7478 - val_loss: 2.0154 - val_acc: 0.4429\n","Epoch 28/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.7041 - acc: 0.7555 - val_loss: 1.9835 - val_acc: 0.4762\n","Epoch 29/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.7020 - acc: 0.7583 - val_loss: 1.8308 - val_acc: 0.6283\n","Epoch 30/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.6965 - acc: 0.7633 - val_loss: 1.9532 - val_acc: 0.5051\n","Epoch 31/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.6993 - acc: 0.7607 - val_loss: 2.1304 - val_acc: 0.3284\n","Epoch 32/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.6939 - acc: 0.7660 - val_loss: 1.8076 - val_acc: 0.6525\n","Epoch 33/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.6907 - acc: 0.7689 - val_loss: 1.9388 - val_acc: 0.5200\n","Epoch 34/500\n","79/79 [==============================] - 51s 642ms/step - loss: 1.6832 - acc: 0.7772 - val_loss: 1.8947 - val_acc: 0.5641\n","Epoch 35/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.6856 - acc: 0.7745 - val_loss: 1.9106 - val_acc: 0.5472\n","Epoch 36/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.6816 - acc: 0.7786 - val_loss: 1.9660 - val_acc: 0.4928\n","Epoch 37/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.6835 - acc: 0.7769 - val_loss: 1.9008 - val_acc: 0.5584\n","Epoch 38/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.6784 - acc: 0.7825 - val_loss: 1.8421 - val_acc: 0.6175\n","Epoch 39/500\n","79/79 [==============================] - 51s 641ms/step - loss: 1.6759 - acc: 0.7844 - val_loss: 1.7933 - val_acc: 0.6662\n","Epoch 40/500\n","79/79 [==============================] - 51s 641ms/step - loss: 1.6723 - acc: 0.7878 - val_loss: 1.7807 - val_acc: 0.6786\n","Epoch 41/500\n","79/79 [==============================] - 51s 641ms/step - loss: 1.6716 - acc: 0.7889 - val_loss: 1.8016 - val_acc: 0.6571\n","Epoch 42/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.6742 - acc: 0.7862 - val_loss: 1.9989 - val_acc: 0.4609\n","Epoch 43/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.6722 - acc: 0.7878 - val_loss: 1.8534 - val_acc: 0.6063\n","Epoch 44/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.6658 - acc: 0.7947 - val_loss: 1.8458 - val_acc: 0.6138\n","Epoch 45/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.6642 - acc: 0.7962 - val_loss: 1.8140 - val_acc: 0.6457\n","Epoch 46/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.6636 - acc: 0.7969 - val_loss: 1.9324 - val_acc: 0.5274\n","Epoch 47/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.6611 - acc: 0.7991 - val_loss: 1.9930 - val_acc: 0.4674\n","Epoch 48/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.6619 - acc: 0.7988 - val_loss: 1.8948 - val_acc: 0.5643\n","Epoch 49/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.6639 - acc: 0.7966 - val_loss: 1.9632 - val_acc: 0.4955\n","Epoch 50/500\n","79/79 [==============================] - 51s 641ms/step - loss: 1.6539 - acc: 0.8065 - val_loss: 1.9341 - val_acc: 0.5263\n","Epoch 51/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.6590 - acc: 0.8013 - val_loss: 2.0005 - val_acc: 0.4588\n","Epoch 52/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.6526 - acc: 0.8078 - val_loss: 1.9691 - val_acc: 0.4909\n","Epoch 53/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.6543 - acc: 0.8059 - val_loss: 1.8354 - val_acc: 0.6240\n","Epoch 54/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.6539 - acc: 0.8063 - val_loss: 1.8427 - val_acc: 0.6174\n","Epoch 55/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.6507 - acc: 0.8098 - val_loss: 1.8482 - val_acc: 0.6116\n","Epoch 56/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.6487 - acc: 0.8119 - val_loss: 1.8316 - val_acc: 0.6284\n","Epoch 57/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.6494 - acc: 0.8108 - val_loss: 1.7624 - val_acc: 0.6979\n","Epoch 58/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.6474 - acc: 0.8126 - val_loss: 1.7989 - val_acc: 0.6606\n","Epoch 59/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.6469 - acc: 0.8137 - val_loss: 1.8299 - val_acc: 0.6301\n","Epoch 60/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.6447 - acc: 0.8159 - val_loss: 1.9328 - val_acc: 0.5269\n","Epoch 61/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.6425 - acc: 0.8180 - val_loss: 2.0405 - val_acc: 0.4185\n","Epoch 62/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.6421 - acc: 0.8184 - val_loss: 1.7655 - val_acc: 0.6948\n","Epoch 63/500\n","79/79 [==============================] - 51s 642ms/step - loss: 1.6392 - acc: 0.8212 - val_loss: 1.8230 - val_acc: 0.6368\n","Epoch 64/500\n","79/79 [==============================] - 51s 646ms/step - loss: 1.6397 - acc: 0.8208 - val_loss: 1.8429 - val_acc: 0.6168\n","Epoch 65/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.6395 - acc: 0.8206 - val_loss: 1.7280 - val_acc: 0.7322\n","Epoch 66/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.6417 - acc: 0.8181 - val_loss: 1.8128 - val_acc: 0.6466\n","Epoch 67/500\n","79/79 [==============================] - 51s 646ms/step - loss: 1.6382 - acc: 0.8221 - val_loss: 1.8715 - val_acc: 0.5891\n","Epoch 68/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.6371 - acc: 0.8233 - val_loss: 1.7633 - val_acc: 0.6967\n","Epoch 69/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.6331 - acc: 0.8275 - val_loss: 1.8710 - val_acc: 0.5903\n","Epoch 70/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.6356 - acc: 0.8249 - val_loss: 1.7603 - val_acc: 0.6995\n","Epoch 71/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.6301 - acc: 0.8305 - val_loss: 1.8079 - val_acc: 0.6526\n","Epoch 72/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.6311 - acc: 0.8293 - val_loss: 1.7966 - val_acc: 0.6634\n","Epoch 73/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.6361 - acc: 0.8244 - val_loss: 1.8409 - val_acc: 0.6193\n","Epoch 74/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.6347 - acc: 0.8261 - val_loss: 1.9469 - val_acc: 0.5137\n","Epoch 75/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.6343 - acc: 0.8264 - val_loss: 1.8526 - val_acc: 0.6081\n","Epoch 76/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.6338 - acc: 0.8268 - val_loss: 1.7573 - val_acc: 0.7028\n","Epoch 77/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.6300 - acc: 0.8306 - val_loss: 1.7773 - val_acc: 0.6831\n","Epoch 78/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.6318 - acc: 0.8288 - val_loss: 1.8447 - val_acc: 0.6153\n","Epoch 79/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.6354 - acc: 0.8253 - val_loss: 1.9029 - val_acc: 0.5573\n","Epoch 80/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.6295 - acc: 0.8313 - val_loss: 1.8106 - val_acc: 0.6495\n","Epoch 81/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.6305 - acc: 0.8302 - val_loss: 1.7977 - val_acc: 0.6619\n","Epoch 82/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.6304 - acc: 0.8302 - val_loss: 1.8166 - val_acc: 0.6444\n","Epoch 83/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.6281 - acc: 0.8328 - val_loss: 1.8253 - val_acc: 0.6352\n","Epoch 84/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.6260 - acc: 0.8346 - val_loss: 1.7847 - val_acc: 0.6754\n","Epoch 85/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.6278 - acc: 0.8331 - val_loss: 1.7906 - val_acc: 0.6693\n","Epoch 86/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.6233 - acc: 0.8375 - val_loss: 1.7173 - val_acc: 0.7434\n","Epoch 87/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.6266 - acc: 0.8345 - val_loss: 1.7638 - val_acc: 0.6960\n","Epoch 88/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.6236 - acc: 0.8373 - val_loss: 1.8486 - val_acc: 0.6114\n","Epoch 89/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.6216 - acc: 0.8388 - val_loss: 1.8499 - val_acc: 0.6098\n","Epoch 90/500\n","79/79 [==============================] - 51s 641ms/step - loss: 1.6248 - acc: 0.8363 - val_loss: 1.7728 - val_acc: 0.6872\n","Epoch 91/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.6251 - acc: 0.8358 - val_loss: 1.7245 - val_acc: 0.7357\n","Epoch 92/500\n","79/79 [==============================] - 51s 641ms/step - loss: 1.6193 - acc: 0.8414 - val_loss: 1.7497 - val_acc: 0.7107\n","Epoch 93/500\n","79/79 [==============================] - 51s 641ms/step - loss: 1.6215 - acc: 0.8393 - val_loss: 1.7747 - val_acc: 0.6853\n","Epoch 94/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.6223 - acc: 0.8382 - val_loss: 1.8110 - val_acc: 0.6499\n","Epoch 95/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.6184 - acc: 0.8425 - val_loss: 1.7290 - val_acc: 0.7315\n","Epoch 96/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.6196 - acc: 0.8411 - val_loss: 1.8065 - val_acc: 0.6539\n","Epoch 97/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.6187 - acc: 0.8420 - val_loss: 1.7904 - val_acc: 0.6701\n","Epoch 98/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.6149 - acc: 0.8459 - val_loss: 1.7589 - val_acc: 0.7013\n","Epoch 99/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.6177 - acc: 0.8430 - val_loss: 1.7551 - val_acc: 0.7052\n","Epoch 100/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.6134 - acc: 0.8475 - val_loss: 1.7503 - val_acc: 0.7102\n","Epoch 101/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.6194 - acc: 0.8414 - val_loss: 1.7700 - val_acc: 0.6901\n","Epoch 102/500\n","79/79 [==============================] - 51s 641ms/step - loss: 1.6149 - acc: 0.8458 - val_loss: 1.7431 - val_acc: 0.7174\n","Epoch 103/500\n","79/79 [==============================] - 51s 641ms/step - loss: 1.6121 - acc: 0.8490 - val_loss: 1.7496 - val_acc: 0.7107\n","Epoch 104/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.6151 - acc: 0.8454 - val_loss: 1.7088 - val_acc: 0.7518\n","Epoch 105/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.6100 - acc: 0.8508 - val_loss: 1.7819 - val_acc: 0.6783\n","Epoch 106/500\n","79/79 [==============================] - 51s 639ms/step - loss: 1.6157 - acc: 0.8449 - val_loss: 1.7594 - val_acc: 0.7013\n","Epoch 107/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.6138 - acc: 0.8468 - val_loss: 1.7893 - val_acc: 0.6712\n","Epoch 108/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.6170 - acc: 0.8440 - val_loss: 1.7875 - val_acc: 0.6724\n","Epoch 109/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.6149 - acc: 0.8461 - val_loss: 1.8145 - val_acc: 0.6470\n","Epoch 110/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.6149 - acc: 0.8456 - val_loss: 1.8613 - val_acc: 0.5987\n","Epoch 111/500\n","79/79 [==============================] - 51s 642ms/step - loss: 1.6103 - acc: 0.8504 - val_loss: 1.8506 - val_acc: 0.6100\n","Epoch 112/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.6127 - acc: 0.8481 - val_loss: 1.7562 - val_acc: 0.7048\n","Epoch 113/500\n","79/79 [==============================] - 51s 646ms/step - loss: 1.6098 - acc: 0.8512 - val_loss: 1.7685 - val_acc: 0.6915\n","Epoch 114/500\n","79/79 [==============================] - 51s 646ms/step - loss: 1.6098 - acc: 0.8509 - val_loss: 1.8366 - val_acc: 0.6239\n","Epoch 115/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.6099 - acc: 0.8508 - val_loss: 1.7238 - val_acc: 0.7368\n","Epoch 116/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.6137 - acc: 0.8472 - val_loss: 1.8912 - val_acc: 0.5691\n","Epoch 117/500\n","79/79 [==============================] - 51s 646ms/step - loss: 1.6092 - acc: 0.8517 - val_loss: 1.7613 - val_acc: 0.6992\n","Epoch 118/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.6108 - acc: 0.8501 - val_loss: 1.7368 - val_acc: 0.7245\n","Epoch 119/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.6159 - acc: 0.8448 - val_loss: 1.7790 - val_acc: 0.6820\n","Epoch 120/500\n","79/79 [==============================] - 51s 642ms/step - loss: 1.6071 - acc: 0.8540 - val_loss: 1.7526 - val_acc: 0.7078\n","Epoch 121/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.6092 - acc: 0.8515 - val_loss: 1.6993 - val_acc: 0.7612\n","Epoch 122/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.6086 - acc: 0.8524 - val_loss: 1.7747 - val_acc: 0.6858\n","Epoch 123/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.6140 - acc: 0.8468 - val_loss: 1.7348 - val_acc: 0.7261\n","Epoch 124/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.6103 - acc: 0.8506 - val_loss: 1.7476 - val_acc: 0.7132\n","Epoch 125/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.6087 - acc: 0.8520 - val_loss: 1.7608 - val_acc: 0.7000\n","Epoch 126/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.6019 - acc: 0.8590 - val_loss: 1.8410 - val_acc: 0.6199\n","Epoch 127/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.6110 - acc: 0.8499 - val_loss: 1.6989 - val_acc: 0.7615\n","Epoch 128/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.6061 - acc: 0.8548 - val_loss: 1.8298 - val_acc: 0.6311\n","Epoch 129/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.6064 - acc: 0.8544 - val_loss: 1.7579 - val_acc: 0.7025\n","Epoch 130/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.6113 - acc: 0.8492 - val_loss: 1.7351 - val_acc: 0.7258\n","Epoch 131/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.6083 - acc: 0.8526 - val_loss: 1.7049 - val_acc: 0.7553\n","Epoch 132/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.6025 - acc: 0.8584 - val_loss: 1.7511 - val_acc: 0.7096\n","Epoch 133/500\n","79/79 [==============================] - 51s 642ms/step - loss: 1.6016 - acc: 0.8591 - val_loss: 1.7108 - val_acc: 0.7500\n","Epoch 134/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.6075 - acc: 0.8533 - val_loss: 1.7649 - val_acc: 0.6957\n","Epoch 135/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.6008 - acc: 0.8604 - val_loss: 1.7159 - val_acc: 0.7454\n","Epoch 136/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.6019 - acc: 0.8589 - val_loss: 1.7405 - val_acc: 0.7201\n","Epoch 137/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.6010 - acc: 0.8597 - val_loss: 1.7989 - val_acc: 0.6623\n","Epoch 138/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.6078 - acc: 0.8533 - val_loss: 1.7892 - val_acc: 0.6715\n","Epoch 139/500\n","79/79 [==============================] - 51s 641ms/step - loss: 1.6084 - acc: 0.8523 - val_loss: 1.8814 - val_acc: 0.5791\n","Epoch 140/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.6073 - acc: 0.8537 - val_loss: 1.7762 - val_acc: 0.6844\n","Epoch 141/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.6052 - acc: 0.8556 - val_loss: 1.7414 - val_acc: 0.7197\n","Epoch 142/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.6056 - acc: 0.8551 - val_loss: 1.8554 - val_acc: 0.6058\n","Epoch 143/500\n","79/79 [==============================] - 51s 641ms/step - loss: 1.6002 - acc: 0.8607 - val_loss: 1.7674 - val_acc: 0.6930\n","Epoch 144/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.6053 - acc: 0.8555 - val_loss: 1.7901 - val_acc: 0.6703\n","Epoch 145/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.6015 - acc: 0.8594 - val_loss: 1.6986 - val_acc: 0.7627\n","Epoch 146/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.5988 - acc: 0.8620 - val_loss: 1.7324 - val_acc: 0.7275\n","Epoch 147/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.5926 - acc: 0.8684 - val_loss: 1.8285 - val_acc: 0.6323\n","Epoch 148/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.6027 - acc: 0.8583 - val_loss: 1.7543 - val_acc: 0.7061\n","Epoch 149/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.5983 - acc: 0.8626 - val_loss: 1.7817 - val_acc: 0.6790\n","Epoch 150/500\n","79/79 [==============================] - 51s 639ms/step - loss: 1.5983 - acc: 0.8626 - val_loss: 1.7275 - val_acc: 0.7332\n","Epoch 151/500\n","79/79 [==============================] - 51s 639ms/step - loss: 1.6014 - acc: 0.8594 - val_loss: 1.7217 - val_acc: 0.7392\n","Epoch 152/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.5984 - acc: 0.8626 - val_loss: 1.7315 - val_acc: 0.7292\n","Epoch 153/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.6014 - acc: 0.8594 - val_loss: 1.7506 - val_acc: 0.7102\n","Epoch 154/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.6009 - acc: 0.8601 - val_loss: 1.6833 - val_acc: 0.7776\n","Epoch 155/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.6015 - acc: 0.8595 - val_loss: 1.8090 - val_acc: 0.6511\n","Epoch 156/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.6047 - acc: 0.8560 - val_loss: 1.7244 - val_acc: 0.7370\n","Epoch 157/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.6060 - acc: 0.8547 - val_loss: 1.7546 - val_acc: 0.7060\n","Epoch 158/500\n","79/79 [==============================] - 51s 642ms/step - loss: 1.5995 - acc: 0.8613 - val_loss: 1.6791 - val_acc: 0.7818\n","Epoch 159/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5993 - acc: 0.8615 - val_loss: 1.7360 - val_acc: 0.7245\n","Epoch 160/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.6005 - acc: 0.8603 - val_loss: 1.8405 - val_acc: 0.6201\n","Epoch 161/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.6002 - acc: 0.8605 - val_loss: 1.7224 - val_acc: 0.7383\n","Epoch 162/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.6023 - acc: 0.8587 - val_loss: 1.7335 - val_acc: 0.7272\n","Epoch 163/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5991 - acc: 0.8618 - val_loss: 1.7188 - val_acc: 0.7425\n","Epoch 164/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5983 - acc: 0.8626 - val_loss: 1.8140 - val_acc: 0.6468\n","Epoch 165/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5960 - acc: 0.8650 - val_loss: 1.6962 - val_acc: 0.7639\n","Epoch 166/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5966 - acc: 0.8642 - val_loss: 1.7991 - val_acc: 0.6612\n","Epoch 167/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5942 - acc: 0.8669 - val_loss: 1.7114 - val_acc: 0.7495\n","Epoch 168/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5946 - acc: 0.8664 - val_loss: 1.7861 - val_acc: 0.6742\n","Epoch 169/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5888 - acc: 0.8721 - val_loss: 1.7062 - val_acc: 0.7542\n","Epoch 170/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5988 - acc: 0.8623 - val_loss: 1.7877 - val_acc: 0.6733\n","Epoch 171/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5932 - acc: 0.8678 - val_loss: 1.7340 - val_acc: 0.7268\n","Epoch 172/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5937 - acc: 0.8672 - val_loss: 1.6825 - val_acc: 0.7783\n","Epoch 173/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5952 - acc: 0.8658 - val_loss: 1.6844 - val_acc: 0.7769\n","Epoch 174/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5938 - acc: 0.8669 - val_loss: 1.7117 - val_acc: 0.7490\n","Epoch 175/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.6005 - acc: 0.8605 - val_loss: 1.7420 - val_acc: 0.7188\n","Epoch 176/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5917 - acc: 0.8691 - val_loss: 1.8373 - val_acc: 0.6238\n","Epoch 177/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5911 - acc: 0.8698 - val_loss: 1.7264 - val_acc: 0.7345\n","Epoch 178/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5931 - acc: 0.8679 - val_loss: 1.6968 - val_acc: 0.7642\n","Epoch 179/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5919 - acc: 0.8689 - val_loss: 1.7433 - val_acc: 0.7172\n","Epoch 180/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5957 - acc: 0.8652 - val_loss: 1.7453 - val_acc: 0.7157\n","Epoch 181/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5892 - acc: 0.8716 - val_loss: 1.7187 - val_acc: 0.7420\n","Epoch 182/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5874 - acc: 0.8736 - val_loss: 1.7046 - val_acc: 0.7560\n","Epoch 183/500\n","79/79 [==============================] - 51s 642ms/step - loss: 1.5878 - acc: 0.8731 - val_loss: 1.6945 - val_acc: 0.7665\n","Epoch 184/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.5935 - acc: 0.8675 - val_loss: 1.7081 - val_acc: 0.7531\n","Epoch 185/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.5901 - acc: 0.8710 - val_loss: 1.6791 - val_acc: 0.7817\n","Epoch 186/500\n","79/79 [==============================] - 51s 641ms/step - loss: 1.5918 - acc: 0.8691 - val_loss: 1.6759 - val_acc: 0.7851\n","Epoch 187/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.5927 - acc: 0.8681 - val_loss: 1.6682 - val_acc: 0.7928\n","Epoch 188/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.5914 - acc: 0.8694 - val_loss: 1.7448 - val_acc: 0.7162\n","Epoch 189/500\n","79/79 [==============================] - 51s 641ms/step - loss: 1.5916 - acc: 0.8693 - val_loss: 1.6714 - val_acc: 0.7897\n","Epoch 190/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.5885 - acc: 0.8725 - val_loss: 1.7294 - val_acc: 0.7314\n","Epoch 191/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.5867 - acc: 0.8743 - val_loss: 1.7107 - val_acc: 0.7506\n","Epoch 192/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.5924 - acc: 0.8685 - val_loss: 1.7428 - val_acc: 0.7183\n","Epoch 193/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.5917 - acc: 0.8692 - val_loss: 1.7081 - val_acc: 0.7527\n","Epoch 194/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.5912 - acc: 0.8695 - val_loss: 1.6882 - val_acc: 0.7728\n","Epoch 195/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.5919 - acc: 0.8691 - val_loss: 1.6866 - val_acc: 0.7741\n","Epoch 196/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.5953 - acc: 0.8658 - val_loss: 1.7242 - val_acc: 0.7369\n","Epoch 197/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.5915 - acc: 0.8694 - val_loss: 1.7112 - val_acc: 0.7498\n","Epoch 198/500\n","79/79 [==============================] - 51s 639ms/step - loss: 1.5906 - acc: 0.8704 - val_loss: 1.7483 - val_acc: 0.7121\n","Epoch 199/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.5923 - acc: 0.8686 - val_loss: 1.7600 - val_acc: 0.7009\n","Epoch 200/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.5961 - acc: 0.8647 - val_loss: 1.7249 - val_acc: 0.7362\n","Epoch 201/500\n","79/79 [==============================] - 51s 641ms/step - loss: 1.5857 - acc: 0.8754 - val_loss: 1.6816 - val_acc: 0.7791\n","Epoch 202/500\n","79/79 [==============================] - 51s 641ms/step - loss: 1.5889 - acc: 0.8720 - val_loss: 1.7713 - val_acc: 0.6895\n","Epoch 203/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.5868 - acc: 0.8742 - val_loss: 1.7376 - val_acc: 0.7234\n","Epoch 204/500\n","79/79 [==============================] - 51s 642ms/step - loss: 1.5916 - acc: 0.8692 - val_loss: 1.7704 - val_acc: 0.6905\n","Epoch 205/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5900 - acc: 0.8711 - val_loss: 1.7402 - val_acc: 0.7208\n","Epoch 206/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5867 - acc: 0.8742 - val_loss: 1.7428 - val_acc: 0.7176\n","Epoch 207/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5856 - acc: 0.8752 - val_loss: 1.7337 - val_acc: 0.7270\n","Epoch 208/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5878 - acc: 0.8732 - val_loss: 1.7007 - val_acc: 0.7601\n","Epoch 209/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5909 - acc: 0.8699 - val_loss: 1.7531 - val_acc: 0.7076\n","Epoch 210/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5918 - acc: 0.8690 - val_loss: 1.7747 - val_acc: 0.6864\n","Epoch 211/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5892 - acc: 0.8719 - val_loss: 1.7420 - val_acc: 0.7188\n","Epoch 212/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5885 - acc: 0.8726 - val_loss: 1.7991 - val_acc: 0.6620\n","Epoch 213/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5895 - acc: 0.8716 - val_loss: 1.7219 - val_acc: 0.7389\n","Epoch 214/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5886 - acc: 0.8722 - val_loss: 1.7382 - val_acc: 0.7224\n","Epoch 215/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5849 - acc: 0.8762 - val_loss: 1.7068 - val_acc: 0.7541\n","Epoch 216/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5888 - acc: 0.8721 - val_loss: 1.6909 - val_acc: 0.7701\n","Epoch 217/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5904 - acc: 0.8705 - val_loss: 1.6823 - val_acc: 0.7783\n","Epoch 218/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5940 - acc: 0.8669 - val_loss: 1.7287 - val_acc: 0.7320\n","Epoch 219/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5895 - acc: 0.8714 - val_loss: 1.7388 - val_acc: 0.7224\n","Epoch 220/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5858 - acc: 0.8753 - val_loss: 1.7179 - val_acc: 0.7429\n","Epoch 221/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5900 - acc: 0.8708 - val_loss: 1.6841 - val_acc: 0.7768\n","Epoch 222/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5884 - acc: 0.8726 - val_loss: 1.7369 - val_acc: 0.7240\n","Epoch 223/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5863 - acc: 0.8748 - val_loss: 1.7109 - val_acc: 0.7499\n","Epoch 224/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5892 - acc: 0.8717 - val_loss: 1.6957 - val_acc: 0.7655\n","Epoch 225/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5874 - acc: 0.8736 - val_loss: 1.6875 - val_acc: 0.7732\n","Epoch 226/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5845 - acc: 0.8765 - val_loss: 1.6950 - val_acc: 0.7658\n","Epoch 227/500\n","79/79 [==============================] - 51s 646ms/step - loss: 1.5894 - acc: 0.8716 - val_loss: 1.6909 - val_acc: 0.7699\n","Epoch 228/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5782 - acc: 0.8827 - val_loss: 1.7099 - val_acc: 0.7512\n","Epoch 229/500\n","79/79 [==============================] - 51s 642ms/step - loss: 1.5846 - acc: 0.8765 - val_loss: 1.7522 - val_acc: 0.7085\n","Epoch 230/500\n","79/79 [==============================] - 51s 642ms/step - loss: 1.5835 - acc: 0.8777 - val_loss: 1.7785 - val_acc: 0.6824\n","Epoch 231/500\n","79/79 [==============================] - 51s 641ms/step - loss: 1.5867 - acc: 0.8744 - val_loss: 1.7501 - val_acc: 0.7111\n","Epoch 232/500\n","79/79 [==============================] - 51s 641ms/step - loss: 1.5951 - acc: 0.8658 - val_loss: 1.7268 - val_acc: 0.7341\n","Epoch 233/500\n","79/79 [==============================] - 51s 642ms/step - loss: 1.5925 - acc: 0.8685 - val_loss: 1.7263 - val_acc: 0.7348\n","Epoch 234/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5859 - acc: 0.8751 - val_loss: 1.7824 - val_acc: 0.6783\n","Epoch 235/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5880 - acc: 0.8728 - val_loss: 1.7056 - val_acc: 0.7553\n","Epoch 236/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5867 - acc: 0.8742 - val_loss: 1.7313 - val_acc: 0.7298\n","Epoch 237/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5874 - acc: 0.8735 - val_loss: 1.7180 - val_acc: 0.7428\n","Epoch 238/500\n","79/79 [==============================] - 51s 642ms/step - loss: 1.5870 - acc: 0.8740 - val_loss: 1.6668 - val_acc: 0.7939\n","Epoch 239/500\n","79/79 [==============================] - 51s 642ms/step - loss: 1.5889 - acc: 0.8722 - val_loss: 1.7076 - val_acc: 0.7534\n","Epoch 240/500\n","79/79 [==============================] - 51s 642ms/step - loss: 1.5825 - acc: 0.8785 - val_loss: 1.7102 - val_acc: 0.7506\n","Epoch 241/500\n","79/79 [==============================] - 51s 642ms/step - loss: 1.5870 - acc: 0.8740 - val_loss: 1.7064 - val_acc: 0.7548\n","Epoch 242/500\n","79/79 [==============================] - 51s 641ms/step - loss: 1.5888 - acc: 0.8722 - val_loss: 1.7788 - val_acc: 0.6818\n","Epoch 243/500\n","79/79 [==============================] - 51s 642ms/step - loss: 1.5867 - acc: 0.8742 - val_loss: 1.7660 - val_acc: 0.6952\n","Epoch 244/500\n","79/79 [==============================] - 51s 642ms/step - loss: 1.5825 - acc: 0.8787 - val_loss: 1.7013 - val_acc: 0.7599\n","Epoch 245/500\n","79/79 [==============================] - 51s 641ms/step - loss: 1.5761 - acc: 0.8849 - val_loss: 1.7094 - val_acc: 0.7513\n","Epoch 246/500\n","79/79 [==============================] - 51s 642ms/step - loss: 1.5914 - acc: 0.8695 - val_loss: 1.7100 - val_acc: 0.7510\n","Epoch 247/500\n","79/79 [==============================] - 51s 642ms/step - loss: 1.5846 - acc: 0.8763 - val_loss: 1.7015 - val_acc: 0.7595\n","Epoch 248/500\n","79/79 [==============================] - 51s 642ms/step - loss: 1.5846 - acc: 0.8765 - val_loss: 1.7046 - val_acc: 0.7563\n","Epoch 249/500\n","79/79 [==============================] - 51s 641ms/step - loss: 1.5804 - acc: 0.8805 - val_loss: 1.6702 - val_acc: 0.7908\n","Epoch 250/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5828 - acc: 0.8784 - val_loss: 1.6614 - val_acc: 0.7995\n","Epoch 251/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5802 - acc: 0.8808 - val_loss: 1.7394 - val_acc: 0.7213\n","Epoch 252/500\n","79/79 [==============================] - 51s 646ms/step - loss: 1.5818 - acc: 0.8791 - val_loss: 1.7253 - val_acc: 0.7354\n","Epoch 253/500\n","79/79 [==============================] - 51s 646ms/step - loss: 1.5867 - acc: 0.8744 - val_loss: 1.7038 - val_acc: 0.7569\n","Epoch 254/500\n","79/79 [==============================] - 51s 646ms/step - loss: 1.5865 - acc: 0.8745 - val_loss: 1.6790 - val_acc: 0.7820\n","Epoch 255/500\n","79/79 [==============================] - 51s 647ms/step - loss: 1.5821 - acc: 0.8790 - val_loss: 1.6855 - val_acc: 0.7753\n","Epoch 256/500\n","79/79 [==============================] - 51s 646ms/step - loss: 1.5836 - acc: 0.8773 - val_loss: 1.6792 - val_acc: 0.7817\n","Epoch 257/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5843 - acc: 0.8769 - val_loss: 1.6876 - val_acc: 0.7733\n","Epoch 258/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5896 - acc: 0.8714 - val_loss: 1.8112 - val_acc: 0.6495\n","Epoch 259/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5850 - acc: 0.8760 - val_loss: 1.7538 - val_acc: 0.7071\n","Epoch 260/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5793 - acc: 0.8816 - val_loss: 1.7069 - val_acc: 0.7538\n","Epoch 261/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5837 - acc: 0.8774 - val_loss: 1.7794 - val_acc: 0.6813\n","Epoch 262/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5870 - acc: 0.8741 - val_loss: 1.6849 - val_acc: 0.7758\n","Epoch 263/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5805 - acc: 0.8805 - val_loss: 1.6693 - val_acc: 0.7917\n","Epoch 264/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5768 - acc: 0.8843 - val_loss: 1.7527 - val_acc: 0.7084\n","Epoch 265/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5855 - acc: 0.8755 - val_loss: 1.7242 - val_acc: 0.7368\n","Epoch 266/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5818 - acc: 0.8792 - val_loss: 1.7179 - val_acc: 0.7432\n","Epoch 267/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5851 - acc: 0.8759 - val_loss: 1.7277 - val_acc: 0.7329\n","Epoch 268/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5820 - acc: 0.8791 - val_loss: 1.6912 - val_acc: 0.7698\n","Epoch 269/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5905 - acc: 0.8705 - val_loss: 1.7935 - val_acc: 0.6675\n","Epoch 270/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5877 - acc: 0.8733 - val_loss: 1.6801 - val_acc: 0.7810\n","Epoch 271/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5857 - acc: 0.8753 - val_loss: 1.6658 - val_acc: 0.7952\n","Epoch 272/500\n","79/79 [==============================] - 51s 642ms/step - loss: 1.5828 - acc: 0.8783 - val_loss: 1.7240 - val_acc: 0.7368\n","Epoch 273/500\n","79/79 [==============================] - 51s 642ms/step - loss: 1.5876 - acc: 0.8734 - val_loss: 1.6933 - val_acc: 0.7674\n","Epoch 274/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5847 - acc: 0.8765 - val_loss: 1.6885 - val_acc: 0.7724\n","Epoch 275/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5877 - acc: 0.8732 - val_loss: 1.7185 - val_acc: 0.7423\n","Epoch 276/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5825 - acc: 0.8786 - val_loss: 1.6932 - val_acc: 0.7676\n","Epoch 277/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5841 - acc: 0.8770 - val_loss: 1.6861 - val_acc: 0.7748\n","Epoch 278/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5822 - acc: 0.8789 - val_loss: 1.7110 - val_acc: 0.7501\n","Epoch 279/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5798 - acc: 0.8813 - val_loss: 1.6866 - val_acc: 0.7743\n","Epoch 280/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5823 - acc: 0.8789 - val_loss: 1.7726 - val_acc: 0.6883\n","Epoch 281/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5833 - acc: 0.8776 - val_loss: 1.7311 - val_acc: 0.7297\n","Epoch 282/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5800 - acc: 0.8811 - val_loss: 1.7281 - val_acc: 0.7329\n","Epoch 283/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5859 - acc: 0.8750 - val_loss: 1.7275 - val_acc: 0.7332\n","Epoch 284/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5843 - acc: 0.8768 - val_loss: 1.7152 - val_acc: 0.7457\n","Epoch 285/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5838 - acc: 0.8772 - val_loss: 1.6911 - val_acc: 0.7700\n","Epoch 286/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5826 - acc: 0.8785 - val_loss: 1.6853 - val_acc: 0.7758\n","Epoch 287/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5852 - acc: 0.8759 - val_loss: 1.6832 - val_acc: 0.7776\n","Epoch 288/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5849 - acc: 0.8763 - val_loss: 1.6723 - val_acc: 0.7888\n","Epoch 289/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5823 - acc: 0.8787 - val_loss: 1.6861 - val_acc: 0.7750\n","Epoch 290/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5849 - acc: 0.8762 - val_loss: 1.6931 - val_acc: 0.7681\n","Epoch 291/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5865 - acc: 0.8745 - val_loss: 1.7227 - val_acc: 0.7382\n","Epoch 292/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5873 - acc: 0.8738 - val_loss: 1.7579 - val_acc: 0.7030\n","Epoch 293/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5862 - acc: 0.8748 - val_loss: 1.7277 - val_acc: 0.7331\n","Epoch 294/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5790 - acc: 0.8820 - val_loss: 1.6868 - val_acc: 0.7741\n","Epoch 295/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5816 - acc: 0.8794 - val_loss: 1.7165 - val_acc: 0.7445\n","Epoch 296/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5907 - acc: 0.8702 - val_loss: 1.6888 - val_acc: 0.7718\n","Epoch 297/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5843 - acc: 0.8767 - val_loss: 1.7192 - val_acc: 0.7419\n","Epoch 298/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5875 - acc: 0.8736 - val_loss: 1.6852 - val_acc: 0.7756\n","Epoch 299/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5819 - acc: 0.8792 - val_loss: 1.7007 - val_acc: 0.7600\n","Epoch 300/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5853 - acc: 0.8758 - val_loss: 1.7325 - val_acc: 0.7285\n","Epoch 301/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5881 - acc: 0.8730 - val_loss: 1.6934 - val_acc: 0.7673\n","Epoch 302/500\n","79/79 [==============================] - 51s 646ms/step - loss: 1.5931 - acc: 0.8680 - val_loss: 1.6834 - val_acc: 0.7775\n","Epoch 303/500\n","79/79 [==============================] - 51s 646ms/step - loss: 1.5862 - acc: 0.8748 - val_loss: 1.7507 - val_acc: 0.7103\n","Epoch 304/500\n","79/79 [==============================] - 51s 646ms/step - loss: 1.5844 - acc: 0.8767 - val_loss: 1.7269 - val_acc: 0.7338\n","Epoch 305/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5883 - acc: 0.8727 - val_loss: 1.7457 - val_acc: 0.7153\n","Epoch 306/500\n","79/79 [==============================] - 51s 646ms/step - loss: 1.5893 - acc: 0.8717 - val_loss: 1.7082 - val_acc: 0.7527\n","Epoch 307/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5883 - acc: 0.8729 - val_loss: 1.6808 - val_acc: 0.7803\n","Epoch 308/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5849 - acc: 0.8763 - val_loss: 1.6723 - val_acc: 0.7889\n","Epoch 309/500\n","79/79 [==============================] - 51s 646ms/step - loss: 1.5831 - acc: 0.8781 - val_loss: 1.7166 - val_acc: 0.7445\n","Epoch 310/500\n","79/79 [==============================] - 51s 646ms/step - loss: 1.5844 - acc: 0.8766 - val_loss: 1.6624 - val_acc: 0.7986\n","Epoch 311/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5846 - acc: 0.8763 - val_loss: 1.6576 - val_acc: 0.8034\n","Epoch 312/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5883 - acc: 0.8727 - val_loss: 1.7315 - val_acc: 0.7294\n","Epoch 313/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5825 - acc: 0.8785 - val_loss: 1.7087 - val_acc: 0.7525\n","Epoch 314/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5856 - acc: 0.8755 - val_loss: 1.7126 - val_acc: 0.7484\n","Epoch 315/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5843 - acc: 0.8766 - val_loss: 1.6853 - val_acc: 0.7755\n","Epoch 316/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5769 - acc: 0.8841 - val_loss: 1.6961 - val_acc: 0.7650\n","Epoch 317/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5755 - acc: 0.8855 - val_loss: 1.7001 - val_acc: 0.7610\n","Epoch 318/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5797 - acc: 0.8814 - val_loss: 1.6883 - val_acc: 0.7725\n","Epoch 319/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5788 - acc: 0.8823 - val_loss: 1.6744 - val_acc: 0.7865\n","Epoch 320/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5760 - acc: 0.8850 - val_loss: 1.7162 - val_acc: 0.7446\n","Epoch 321/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5780 - acc: 0.8831 - val_loss: 1.6788 - val_acc: 0.7822\n","Epoch 322/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5776 - acc: 0.8835 - val_loss: 1.7080 - val_acc: 0.7531\n","Epoch 323/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5800 - acc: 0.8811 - val_loss: 1.6823 - val_acc: 0.7787\n","Epoch 324/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5802 - acc: 0.8807 - val_loss: 1.6642 - val_acc: 0.7969\n","Epoch 325/500\n","79/79 [==============================] - 51s 646ms/step - loss: 1.5773 - acc: 0.8837 - val_loss: 1.6758 - val_acc: 0.7854\n","Epoch 326/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5804 - acc: 0.8806 - val_loss: 1.6829 - val_acc: 0.7781\n","Epoch 327/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5794 - acc: 0.8816 - val_loss: 1.6715 - val_acc: 0.7896\n","Epoch 328/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5767 - acc: 0.8843 - val_loss: 1.6941 - val_acc: 0.7671\n","Epoch 329/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5770 - acc: 0.8840 - val_loss: 1.6637 - val_acc: 0.7974\n","Epoch 330/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5831 - acc: 0.8779 - val_loss: 1.6645 - val_acc: 0.7964\n","Epoch 331/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5852 - acc: 0.8759 - val_loss: 1.7098 - val_acc: 0.7512\n","Epoch 332/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5786 - acc: 0.8824 - val_loss: 1.6576 - val_acc: 0.8034\n","Epoch 333/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5781 - acc: 0.8828 - val_loss: 1.6859 - val_acc: 0.7752\n","Epoch 334/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5800 - acc: 0.8810 - val_loss: 1.6966 - val_acc: 0.7644\n","Epoch 335/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5796 - acc: 0.8814 - val_loss: 1.6770 - val_acc: 0.7840\n","Epoch 336/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5752 - acc: 0.8860 - val_loss: 1.7088 - val_acc: 0.7522\n","Epoch 337/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5768 - acc: 0.8842 - val_loss: 1.7012 - val_acc: 0.7597\n","Epoch 338/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5758 - acc: 0.8854 - val_loss: 1.6674 - val_acc: 0.7937\n","Epoch 339/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5749 - acc: 0.8861 - val_loss: 1.6707 - val_acc: 0.7899\n","Epoch 340/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5767 - acc: 0.8844 - val_loss: 1.6918 - val_acc: 0.7692\n","Epoch 341/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5793 - acc: 0.8817 - val_loss: 1.7013 - val_acc: 0.7597\n","Epoch 342/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5756 - acc: 0.8855 - val_loss: 1.7861 - val_acc: 0.6748\n","Epoch 343/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5826 - acc: 0.8784 - val_loss: 1.6683 - val_acc: 0.7926\n","Epoch 344/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5773 - acc: 0.8838 - val_loss: 1.6830 - val_acc: 0.7781\n","Epoch 345/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5763 - acc: 0.8846 - val_loss: 1.6891 - val_acc: 0.7719\n","Epoch 346/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5827 - acc: 0.8783 - val_loss: 1.6959 - val_acc: 0.7653\n","Epoch 347/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5818 - acc: 0.8793 - val_loss: 1.8215 - val_acc: 0.6392\n","Epoch 348/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5725 - acc: 0.8886 - val_loss: 1.7080 - val_acc: 0.7527\n","Epoch 349/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5740 - acc: 0.8871 - val_loss: 1.7201 - val_acc: 0.7409\n","Epoch 350/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5788 - acc: 0.8822 - val_loss: 1.7157 - val_acc: 0.7455\n","Epoch 351/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5793 - acc: 0.8818 - val_loss: 1.6813 - val_acc: 0.7797\n","Epoch 352/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5765 - acc: 0.8846 - val_loss: 1.6763 - val_acc: 0.7846\n","Epoch 353/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5829 - acc: 0.8781 - val_loss: 1.7153 - val_acc: 0.7458\n","Epoch 354/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5778 - acc: 0.8832 - val_loss: 1.6787 - val_acc: 0.7823\n","Epoch 355/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5841 - acc: 0.8771 - val_loss: 1.7164 - val_acc: 0.7445\n","Epoch 356/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5795 - acc: 0.8816 - val_loss: 1.7100 - val_acc: 0.7509\n","Epoch 357/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5784 - acc: 0.8826 - val_loss: 1.7352 - val_acc: 0.7257\n","Epoch 358/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5838 - acc: 0.8772 - val_loss: 1.6807 - val_acc: 0.7803\n","Epoch 359/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5784 - acc: 0.8826 - val_loss: 1.7859 - val_acc: 0.6752\n","Epoch 360/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5793 - acc: 0.8819 - val_loss: 1.7257 - val_acc: 0.7355\n","Epoch 361/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5753 - acc: 0.8857 - val_loss: 1.6929 - val_acc: 0.7684\n","Epoch 362/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5788 - acc: 0.8823 - val_loss: 1.6865 - val_acc: 0.7746\n","Epoch 363/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5765 - acc: 0.8845 - val_loss: 1.7228 - val_acc: 0.7381\n","Epoch 364/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5815 - acc: 0.8795 - val_loss: 1.6992 - val_acc: 0.7619\n","Epoch 365/500\n","79/79 [==============================] - 51s 646ms/step - loss: 1.5792 - acc: 0.8820 - val_loss: 1.6834 - val_acc: 0.7774\n","Epoch 366/500\n","79/79 [==============================] - 51s 646ms/step - loss: 1.5750 - acc: 0.8860 - val_loss: 1.7187 - val_acc: 0.7424\n","Epoch 367/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5807 - acc: 0.8803 - val_loss: 1.7027 - val_acc: 0.7582\n","Epoch 368/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5856 - acc: 0.8755 - val_loss: 1.6870 - val_acc: 0.7739\n","Epoch 369/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5796 - acc: 0.8815 - val_loss: 1.6677 - val_acc: 0.7933\n","Epoch 370/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5720 - acc: 0.8891 - val_loss: 1.6599 - val_acc: 0.8013\n","Epoch 371/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5779 - acc: 0.8833 - val_loss: 1.7044 - val_acc: 0.7567\n","Epoch 372/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5816 - acc: 0.8795 - val_loss: 1.6829 - val_acc: 0.7779\n","Epoch 373/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5780 - acc: 0.8831 - val_loss: 1.7133 - val_acc: 0.7475\n","Epoch 374/500\n","79/79 [==============================] - 51s 642ms/step - loss: 1.5752 - acc: 0.8859 - val_loss: 1.6806 - val_acc: 0.7803\n","Epoch 375/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5721 - acc: 0.8891 - val_loss: 1.7260 - val_acc: 0.7347\n","Epoch 376/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5781 - acc: 0.8830 - val_loss: 1.7090 - val_acc: 0.7519\n","Epoch 377/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5803 - acc: 0.8808 - val_loss: 1.6679 - val_acc: 0.7931\n","Epoch 378/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5740 - acc: 0.8870 - val_loss: 1.7020 - val_acc: 0.7588\n","Epoch 379/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5788 - acc: 0.8823 - val_loss: 1.6950 - val_acc: 0.7660\n","Epoch 380/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5752 - acc: 0.8858 - val_loss: 1.6721 - val_acc: 0.7890\n","Epoch 381/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5781 - acc: 0.8830 - val_loss: 1.6968 - val_acc: 0.7638\n","Epoch 382/500\n","79/79 [==============================] - 51s 642ms/step - loss: 1.5695 - acc: 0.8917 - val_loss: 1.7288 - val_acc: 0.7319\n","Epoch 383/500\n","79/79 [==============================] - 51s 642ms/step - loss: 1.5756 - acc: 0.8855 - val_loss: 1.7247 - val_acc: 0.7363\n","Epoch 384/500\n","79/79 [==============================] - 51s 642ms/step - loss: 1.5833 - acc: 0.8778 - val_loss: 1.7089 - val_acc: 0.7519\n","Epoch 385/500\n","79/79 [==============================] - 51s 642ms/step - loss: 1.5774 - acc: 0.8837 - val_loss: 1.7182 - val_acc: 0.7425\n","Epoch 386/500\n","79/79 [==============================] - 51s 642ms/step - loss: 1.5729 - acc: 0.8881 - val_loss: 1.6717 - val_acc: 0.7894\n","Epoch 387/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5733 - acc: 0.8876 - val_loss: 1.6738 - val_acc: 0.7871\n","Epoch 388/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5745 - acc: 0.8867 - val_loss: 1.7436 - val_acc: 0.7175\n","Epoch 389/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5753 - acc: 0.8857 - val_loss: 1.6814 - val_acc: 0.7794\n","Epoch 390/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5748 - acc: 0.8863 - val_loss: 1.6533 - val_acc: 0.8077\n","Epoch 391/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5712 - acc: 0.8900 - val_loss: 1.6606 - val_acc: 0.8004\n","Epoch 392/500\n","79/79 [==============================] - 51s 642ms/step - loss: 1.5787 - acc: 0.8823 - val_loss: 1.6871 - val_acc: 0.7738\n","Epoch 393/500\n","79/79 [==============================] - 51s 642ms/step - loss: 1.5749 - acc: 0.8861 - val_loss: 1.7152 - val_acc: 0.7460\n","Epoch 394/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5731 - acc: 0.8880 - val_loss: 1.6640 - val_acc: 0.7968\n","Epoch 395/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5765 - acc: 0.8846 - val_loss: 1.6883 - val_acc: 0.7728\n","Epoch 396/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5759 - acc: 0.8851 - val_loss: 1.7031 - val_acc: 0.7578\n","Epoch 397/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5780 - acc: 0.8831 - val_loss: 1.6554 - val_acc: 0.8057\n","Epoch 398/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5730 - acc: 0.8881 - val_loss: 1.6644 - val_acc: 0.7966\n","Epoch 399/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5719 - acc: 0.8891 - val_loss: 1.6636 - val_acc: 0.7974\n","Epoch 400/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5771 - acc: 0.8840 - val_loss: 1.7108 - val_acc: 0.7500\n","Epoch 401/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5823 - acc: 0.8788 - val_loss: 1.6760 - val_acc: 0.7851\n","Epoch 402/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5777 - acc: 0.8834 - val_loss: 1.6884 - val_acc: 0.7726\n","Epoch 403/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5781 - acc: 0.8830 - val_loss: 1.6791 - val_acc: 0.7822\n","Epoch 404/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5734 - acc: 0.8876 - val_loss: 1.7047 - val_acc: 0.7562\n","Epoch 405/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5727 - acc: 0.8885 - val_loss: 1.6910 - val_acc: 0.7700\n","Epoch 406/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5711 - acc: 0.8899 - val_loss: 1.6606 - val_acc: 0.8006\n","Epoch 407/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5747 - acc: 0.8863 - val_loss: 1.6873 - val_acc: 0.7740\n","Epoch 408/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5820 - acc: 0.8791 - val_loss: 1.7086 - val_acc: 0.7527\n","Epoch 409/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5818 - acc: 0.8793 - val_loss: 1.7297 - val_acc: 0.7313\n","Epoch 410/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5799 - acc: 0.8811 - val_loss: 1.6846 - val_acc: 0.7766\n","Epoch 411/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5740 - acc: 0.8871 - val_loss: 1.6836 - val_acc: 0.7775\n","Epoch 412/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5731 - acc: 0.8880 - val_loss: 1.7912 - val_acc: 0.6697\n","Epoch 413/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5759 - acc: 0.8852 - val_loss: 1.6946 - val_acc: 0.7665\n","Epoch 414/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5802 - acc: 0.8808 - val_loss: 1.6882 - val_acc: 0.7730\n","Epoch 415/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5736 - acc: 0.8875 - val_loss: 1.6754 - val_acc: 0.7857\n","Epoch 416/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5701 - acc: 0.8910 - val_loss: 1.6865 - val_acc: 0.7746\n","Epoch 417/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5703 - acc: 0.8907 - val_loss: 1.6776 - val_acc: 0.7836\n","Epoch 418/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5735 - acc: 0.8875 - val_loss: 1.6657 - val_acc: 0.7953\n","Epoch 419/500\n","79/79 [==============================] - 51s 646ms/step - loss: 1.5708 - acc: 0.8903 - val_loss: 1.6566 - val_acc: 0.8045\n","Epoch 420/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5685 - acc: 0.8926 - val_loss: 1.6761 - val_acc: 0.7852\n","Epoch 421/500\n","79/79 [==============================] - 51s 642ms/step - loss: 1.5746 - acc: 0.8865 - val_loss: 1.6551 - val_acc: 0.8062\n","Epoch 422/500\n","79/79 [==============================] - 51s 642ms/step - loss: 1.5707 - acc: 0.8905 - val_loss: 1.6768 - val_acc: 0.7843\n","Epoch 423/500\n","79/79 [==============================] - 51s 642ms/step - loss: 1.5696 - acc: 0.8915 - val_loss: 1.6629 - val_acc: 0.7981\n","Epoch 424/500\n","79/79 [==============================] - 51s 642ms/step - loss: 1.5732 - acc: 0.8878 - val_loss: 1.6540 - val_acc: 0.8073\n","Epoch 425/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5736 - acc: 0.8874 - val_loss: 1.6918 - val_acc: 0.7691\n","Epoch 426/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5699 - acc: 0.8911 - val_loss: 1.6823 - val_acc: 0.7788\n","Epoch 427/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5784 - acc: 0.8826 - val_loss: 1.6720 - val_acc: 0.7890\n","Epoch 428/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5687 - acc: 0.8924 - val_loss: 1.6821 - val_acc: 0.7789\n","Epoch 429/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5689 - acc: 0.8921 - val_loss: 1.6595 - val_acc: 0.8014\n","Epoch 430/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5758 - acc: 0.8853 - val_loss: 1.7068 - val_acc: 0.7542\n","Epoch 431/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5751 - acc: 0.8860 - val_loss: 1.6903 - val_acc: 0.7708\n","Epoch 432/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5744 - acc: 0.8866 - val_loss: 1.7050 - val_acc: 0.7560\n","Epoch 433/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5721 - acc: 0.8890 - val_loss: 1.6717 - val_acc: 0.7892\n","Epoch 434/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5715 - acc: 0.8896 - val_loss: 1.6879 - val_acc: 0.7733\n","Epoch 435/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5737 - acc: 0.8874 - val_loss: 1.6628 - val_acc: 0.7981\n","Epoch 436/500\n","79/79 [==============================] - 51s 642ms/step - loss: 1.5713 - acc: 0.8899 - val_loss: 1.6748 - val_acc: 0.7862\n","Epoch 437/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5701 - acc: 0.8910 - val_loss: 1.6836 - val_acc: 0.7775\n","Epoch 438/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5742 - acc: 0.8869 - val_loss: 1.6822 - val_acc: 0.7787\n","Epoch 439/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5721 - acc: 0.8890 - val_loss: 1.7360 - val_acc: 0.7251\n","Epoch 440/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5695 - acc: 0.8917 - val_loss: 1.6693 - val_acc: 0.7916\n","Epoch 441/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5722 - acc: 0.8889 - val_loss: 1.6645 - val_acc: 0.7964\n","Epoch 442/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5716 - acc: 0.8894 - val_loss: 1.7287 - val_acc: 0.7321\n","Epoch 443/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5739 - acc: 0.8872 - val_loss: 1.7105 - val_acc: 0.7504\n","Epoch 444/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5696 - acc: 0.8916 - val_loss: 1.7045 - val_acc: 0.7567\n","Epoch 445/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5686 - acc: 0.8925 - val_loss: 1.6845 - val_acc: 0.7768\n","Epoch 446/500\n","79/79 [==============================] - 51s 646ms/step - loss: 1.5713 - acc: 0.8898 - val_loss: 1.6584 - val_acc: 0.8026\n","Epoch 447/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5691 - acc: 0.8921 - val_loss: 1.7000 - val_acc: 0.7611\n","Epoch 448/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5698 - acc: 0.8912 - val_loss: 1.6611 - val_acc: 0.7999\n","Epoch 449/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5737 - acc: 0.8875 - val_loss: 1.6680 - val_acc: 0.7933\n","Epoch 450/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5707 - acc: 0.8904 - val_loss: 1.6682 - val_acc: 0.7930\n","Epoch 451/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5772 - acc: 0.8839 - val_loss: 1.6783 - val_acc: 0.7829\n","Epoch 452/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5776 - acc: 0.8835 - val_loss: 1.6719 - val_acc: 0.7892\n","Epoch 453/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5774 - acc: 0.8837 - val_loss: 1.6858 - val_acc: 0.7751\n","Epoch 454/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5783 - acc: 0.8828 - val_loss: 1.6913 - val_acc: 0.7697\n","Epoch 455/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5731 - acc: 0.8879 - val_loss: 1.6958 - val_acc: 0.7650\n","Epoch 456/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5774 - acc: 0.8837 - val_loss: 1.7089 - val_acc: 0.7523\n","Epoch 457/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5763 - acc: 0.8848 - val_loss: 1.7039 - val_acc: 0.7572\n","Epoch 458/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5736 - acc: 0.8874 - val_loss: 1.6855 - val_acc: 0.7754\n","Epoch 459/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5762 - acc: 0.8849 - val_loss: 1.6777 - val_acc: 0.7831\n","Epoch 460/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5726 - acc: 0.8884 - val_loss: 1.6742 - val_acc: 0.7869\n","Epoch 461/500\n","79/79 [==============================] - 51s 642ms/step - loss: 1.5712 - acc: 0.8898 - val_loss: 1.6829 - val_acc: 0.7781\n","Epoch 462/500\n","79/79 [==============================] - 51s 644ms/step - loss: 1.5708 - acc: 0.8902 - val_loss: 1.6812 - val_acc: 0.7798\n","Epoch 463/500\n","79/79 [==============================] - 51s 645ms/step - loss: 1.5716 - acc: 0.8895 - val_loss: 1.6903 - val_acc: 0.7708\n","Epoch 464/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5745 - acc: 0.8866 - val_loss: 1.6684 - val_acc: 0.7925\n","Epoch 465/500\n","79/79 [==============================] - 51s 642ms/step - loss: 1.5677 - acc: 0.8934 - val_loss: 1.6865 - val_acc: 0.7750\n","Epoch 466/500\n","79/79 [==============================] - 51s 642ms/step - loss: 1.5785 - acc: 0.8825 - val_loss: 1.6749 - val_acc: 0.7864\n","Epoch 467/500\n","79/79 [==============================] - 51s 641ms/step - loss: 1.5764 - acc: 0.8848 - val_loss: 1.7287 - val_acc: 0.7324\n","Epoch 468/500\n","79/79 [==============================] - 51s 641ms/step - loss: 1.5746 - acc: 0.8866 - val_loss: 1.6825 - val_acc: 0.7786\n","Epoch 469/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.5696 - acc: 0.8914 - val_loss: 1.6732 - val_acc: 0.7878\n","Epoch 470/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.5732 - acc: 0.8878 - val_loss: 1.6965 - val_acc: 0.7645\n","Epoch 471/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.5728 - acc: 0.8883 - val_loss: 1.6865 - val_acc: 0.7747\n","Epoch 472/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.5744 - acc: 0.8867 - val_loss: 1.6735 - val_acc: 0.7877\n","Epoch 473/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5706 - acc: 0.8905 - val_loss: 1.6844 - val_acc: 0.7768\n","Epoch 474/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.5686 - acc: 0.8926 - val_loss: 1.6964 - val_acc: 0.7645\n","Epoch 475/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.5744 - acc: 0.8867 - val_loss: 1.6630 - val_acc: 0.7981\n","Epoch 476/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.5726 - acc: 0.8884 - val_loss: 1.6758 - val_acc: 0.7850\n","Epoch 477/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.5700 - acc: 0.8911 - val_loss: 1.6669 - val_acc: 0.7945\n","Epoch 478/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.5696 - acc: 0.8915 - val_loss: 1.6774 - val_acc: 0.7840\n","Epoch 479/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.5697 - acc: 0.8913 - val_loss: 1.6884 - val_acc: 0.7726\n","Epoch 480/500\n","79/79 [==============================] - 51s 639ms/step - loss: 1.5631 - acc: 0.8979 - val_loss: 1.7165 - val_acc: 0.7445\n","Epoch 481/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.5710 - acc: 0.8901 - val_loss: 1.7224 - val_acc: 0.7386\n","Epoch 482/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.5702 - acc: 0.8909 - val_loss: 1.6831 - val_acc: 0.7781\n","Epoch 483/500\n","79/79 [==============================] - 51s 639ms/step - loss: 1.5717 - acc: 0.8893 - val_loss: 1.7322 - val_acc: 0.7288\n","Epoch 484/500\n","79/79 [==============================] - 51s 640ms/step - loss: 1.5745 - acc: 0.8867 - val_loss: 1.6628 - val_acc: 0.7984\n","Epoch 485/500\n","79/79 [==============================] - 51s 641ms/step - loss: 1.5665 - acc: 0.8945 - val_loss: 1.6620 - val_acc: 0.7991\n","Epoch 486/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5677 - acc: 0.8933 - val_loss: 1.7306 - val_acc: 0.7307\n","Epoch 487/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5706 - acc: 0.8906 - val_loss: 1.6828 - val_acc: 0.7781\n","Epoch 488/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5693 - acc: 0.8917 - val_loss: 1.6765 - val_acc: 0.7846\n","Epoch 489/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5779 - acc: 0.8831 - val_loss: 1.6685 - val_acc: 0.7925\n","Epoch 490/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5753 - acc: 0.8859 - val_loss: 1.6834 - val_acc: 0.7777\n","Epoch 491/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5640 - acc: 0.8971 - val_loss: 1.7180 - val_acc: 0.7434\n","Epoch 492/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5650 - acc: 0.8961 - val_loss: 1.7240 - val_acc: 0.7372\n","Epoch 493/500\n","79/79 [==============================] - 51s 642ms/step - loss: 1.5648 - acc: 0.8963 - val_loss: 1.6781 - val_acc: 0.7829\n","Epoch 494/500\n","79/79 [==============================] - 51s 642ms/step - loss: 1.5656 - acc: 0.8954 - val_loss: 1.6589 - val_acc: 0.8019\n","Epoch 495/500\n","79/79 [==============================] - 51s 642ms/step - loss: 1.5673 - acc: 0.8938 - val_loss: 1.6855 - val_acc: 0.7757\n","Epoch 496/500\n","79/79 [==============================] - 51s 642ms/step - loss: 1.5681 - acc: 0.8930 - val_loss: 1.6555 - val_acc: 0.8056\n","Epoch 497/500\n","79/79 [==============================] - 51s 642ms/step - loss: 1.5609 - acc: 0.9002 - val_loss: 1.6791 - val_acc: 0.7819\n","Epoch 498/500\n","79/79 [==============================] - 51s 642ms/step - loss: 1.5676 - acc: 0.8935 - val_loss: 1.7033 - val_acc: 0.7577\n","Epoch 499/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5692 - acc: 0.8920 - val_loss: 1.6533 - val_acc: 0.8081\n","Epoch 500/500\n","79/79 [==============================] - 51s 643ms/step - loss: 1.5712 - acc: 0.8898 - val_loss: 1.6977 - val_acc: 0.7633\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"I27AdU-kyQ_C","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1592945280240,"user_tz":-540,"elapsed":25758888,"user":{"displayName":"안태진","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsxFAp9n5vXMpfFrx0yqs7oGvvO0UQmgnJGXAJw=s64","userId":"04391961696214707238"}},"outputId":"19c647c3-ba6f-4f94-de83-de513e0e8f84"},"source":["evaluation = model.evaluate( x_test, y_test )\n","print( f'loss: {evaluation[0]:.2f}, acc: {evaluation[1]*100:.2f}%' )"],"execution_count":null,"outputs":[{"output_type":"stream","text":["313/313 [==============================] - 6s 19ms/step - loss: 1.7003 - acc: 0.7606\n","loss: 1.70, acc: 76.06%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7GOphUGLyQ_E","colab_type":"code","colab":{}},"source":["model.save( model_name + '.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P0WnDgZSyQ_G","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":295},"executionInfo":{"status":"ok","timestamp":1592945281589,"user_tz":-540,"elapsed":25760234,"user":{"displayName":"안태진","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsxFAp9n5vXMpfFrx0yqs7oGvvO0UQmgnJGXAJw=s64","userId":"04391961696214707238"}},"outputId":"5238a182-59b7-4ae4-f1aa-e83f53891033"},"source":["%matplotlib inline\n","import matplotlib.pyplot as plt\n","plt.plot( history.history['acc'] )\n","plt.plot( history.history['val_acc'])\n","plt.xlabel( 'epochs' )\n","plt.ylabel( 'acc' )\n","plt.legend( ['acc', 'val_acc'] )\n","plt.title( model_name )\n","\n","plt.savefig( model_name + '.png')\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]}]}